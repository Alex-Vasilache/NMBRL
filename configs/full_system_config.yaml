# Global configuration for the entire run
global:
  seed: 42
  run_folder_prefix: "runs"

# Configuration for the main run_full_system.py script
run_system:
  head_start_seconds: 1
  create_new_consoles: true # If false, output will be piped to the main console

# Configuration for learning/dynamic_data_generator.py
data_generator:
  max_episode_steps: 2000
  actor_check_interval_seconds: 1
  buffer_write_interval_seconds: 3

# Configuration for learning/dynamic_train_world_model.py
world_model_trainer:
  # Training trigger settings
  new_data_threshold: 4000
  watcher_interval_seconds: 3
  # Model architecture
  hidden_dim: 2048
  # Training parameters
  buffer_policy: "oldest_n" # "latest" or "random", "oldest_n"
  batch_size: "all" # "all" or an integer value
  epochs_per_cycle: 10000
  learning_rate: 0.00001
  validation_split: 0.2
  # Learning rate scheduler settings
  lr_patience: 5
  lr_factor: 0.3

# Configuration for learning/dynamic_train_agent_sb3.py
agent_trainer:
  agent_type: "SAC" # "PPO" or "SAC"
  # Environment settings
  n_envs: 16
  max_episode_steps: 15
  # Training run settings
  total_timesteps: 10000000
  # Callback settings
  checkpoint_freq: 1000
  verbose: 0

  # Settings for the world model wrapper used by the SAC agent
  world_model_wrapper:
    model_check_interval_s: 1
    obs_clip_range: 5.0
    reward_clip_range: [-1.0, 1.0] 