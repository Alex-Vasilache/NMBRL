# Global configuration for the entire run
global:
  seed: 42
  run_folder_prefix: "runs"

# Configuration for the main run_full_system.py script
run_system:
  head_start_seconds: 1
  create_new_consoles: false # If false, output will be piped to the main console

# Configuration for learning/dynamic_data_generator.py
data_generator:
  max_episode_steps: 1000
  actor_check_interval_seconds: 1
  buffer_write_interval_seconds: 1

# Configuration for learning/dynamic_train_world_model.py
world_model_trainer:
  # Training trigger settings
  new_data_threshold: 1024
  watcher_interval_seconds: 1
  # Model architecture
  hidden_dim: 512
  # Training parameters
  buffer_policy: "latest" # "latest" or "random"
  batch_size: "all" # "all" or an integer value
  epochs_per_cycle: 10000
  learning_rate: 0.00001
  validation_split: 0.2
  # Learning rate scheduler settings
  lr_patience: 5
  lr_factor: 0.3

# Configuration for learning/dynamic_train_agent_sb3.py
agent_trainer:
  agent_type: "SAC" # "PPO" or "SAC"
  # Environment settings
  n_envs: 16
  max_episode_steps: 1000
  # Training run settings
  total_timesteps: 100000
  # Callback settings
  eval_freq: 1000
  checkpoint_freq: 500

  # Settings for the world model wrapper used by the SAC agent
  world_model_wrapper:
    model_check_interval_s: 1
    obs_clip_range: 10.0
    reward_clip_range: [-2.0, 2.0] 