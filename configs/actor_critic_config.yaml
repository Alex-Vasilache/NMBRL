# Training
num_epochs: 1000
batch_size: 32
learning_rate: 1e-4
eps: 1e-5
grad_clip: 100.0
max_steps_per_episode: 10000
device: 'cpu'
reward_EMA: True
seed: 42
deterministic_run: False


# Behavior
gamma: 0.997            # Discount factor for the reward
discount_lambda: 0.95   # return mixing factor
imag_horizon: 15        # Horizon for imagined trajectories

# Simulation 
visualize: False
dt_simulation: 0.02

# Model
act: 'SiLU'             # Activation function
norm: True              # Layer Normalization
units: 128               # Number of neurons in each layer

# Logging
save_dir: "saved_models"  # Directory to save trained models
log_dir: "runs"  # Directory for TensorBoard logs
save_frequency: 30  # Save models every N episodes (None to disable)

# Evaluation (runs at same frequency as saves)
eval_episodes: 5  # Number of episodes for intermediate evaluation
eval_visualize: false  # Whether to visualize during intermediate evaluation
final_eval_episodes: 10  # Number of episodes for final evaluation

# Actor
actor:
  layers: 2
  dist: 'normal'
  entropy: 3e-4
  unimix_ratio: 0.01
  std: 'learned'
  min_std: 0.1
  max_std: 1.0
  temp: 0.1
  outscale: 1.0

# Critic
critic:
  layers: 2
  dist: 'symlog_disc'
  outscale: 0.0
  slow_target: True
  slow_target_update: 1
  slow_target_fraction: 0.02